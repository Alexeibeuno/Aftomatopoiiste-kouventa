{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35088b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7003c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"C:/Users/91866/Downloads/archive (3)\"\n",
    "files_list = os.listdir(dir_path + os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa8ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1894\n"
     ]
    }
   ],
   "source": [
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db79e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9428ccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\91866\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eee244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "  vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "  tokens_list = []\n",
    "  vocabulary = []\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    tokens = sentence.split()\n",
    "    vocabulary += tokens\n",
    "    tokens_list.append(tokens)\n",
    "  return tokens_list, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88109fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 22) 22\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae30583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74) 74\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e89a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74, 1894)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e0ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 74)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 22, 200)      378800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 74, 200)      378800      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 74, 200),    320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 74, 1894)     380694      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,779,894\n",
      "Trainable params: 1,779,894\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c62f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 20s 658ms/step - loss: 1.2978\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 10s 866ms/step - loss: 1.1172\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 6s 361ms/step - loss: 1.0945\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 8s 722ms/step - loss: 1.0745\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 8s 478ms/step - loss: 1.0558\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 1.0392\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.0245\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 10s 886ms/step - loss: 1.0102\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 6s 382ms/step - loss: 0.9969\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 11s 933ms/step - loss: 0.9828\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 5s 373ms/step - loss: 0.9675\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 10s 836ms/step - loss: 0.9539\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 6s 378ms/step - loss: 0.9386\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 10s 902ms/step - loss: 0.9235\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 6s 381ms/step - loss: 0.9096\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 9s 743ms/step - loss: 0.8957\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 8s 422ms/step - loss: 0.8819\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.8674\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 5s 379ms/step - loss: 0.8540\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.8411\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 5s 390ms/step - loss: 0.8283\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.8149\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 5s 450ms/step - loss: 0.8024\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 11s 997ms/step - loss: 0.7913\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 0.7775\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.7665\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 0.7556\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 11s 882ms/step - loss: 0.7424\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 0.7318\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 11s 754ms/step - loss: 0.7211\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 4s 346ms/step - loss: 0.7096\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 11s 969ms/step - loss: 0.6987\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 4s 348ms/step - loss: 0.6879\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 11s 958ms/step - loss: 0.6764\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 0.6664\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 11s 998ms/step - loss: 0.6562\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 5s 399ms/step - loss: 0.6462\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 5s 397ms/step - loss: 0.6359\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.6245\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.6154\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 5s 372ms/step - loss: 0.6053\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.5953\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 5s 383ms/step - loss: 0.5849\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 5s 379ms/step - loss: 0.5756\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 4s 374ms/step - loss: 0.5658\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.5554\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.5480\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 4s 356ms/step - loss: 0.5361\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.5281\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.5182\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.5094\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.4989\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 5s 385ms/step - loss: 0.4901\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 5s 387ms/step - loss: 0.4809\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 5s 383ms/step - loss: 0.4724\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 5s 392ms/step - loss: 0.4623\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 5s 406ms/step - loss: 0.4559\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 0.4461\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.4368\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 0.4287\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 5s 411ms/step - loss: 0.4199\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 6s 477ms/step - loss: 0.4113\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.4054\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.3939\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 5s 416ms/step - loss: 0.3872\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 5s 434ms/step - loss: 0.3790\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.3707\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 5s 411ms/step - loss: 0.3652\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.3552\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 5s 403ms/step - loss: 0.3478\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.3417\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.3324\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.3270\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.3186\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 5s 413ms/step - loss: 0.3121\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 0.3047\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 5s 450ms/step - loss: 0.2988\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 5s 447ms/step - loss: 0.2929\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 5s 438ms/step - loss: 0.2851\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.2784\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 6s 459ms/step - loss: 0.2727\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 6s 464ms/step - loss: 0.2663\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 6s 469ms/step - loss: 0.2603\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 5s 422ms/step - loss: 0.2532\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 0.2482\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 5s 415ms/step - loss: 0.2417\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.2359\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 5s 406ms/step - loss: 0.2317\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.2246\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 0.2202\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 0.2144\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 5s 406ms/step - loss: 0.2087\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 5s 402ms/step - loss: 0.2051\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 5s 406ms/step - loss: 0.1995\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 5s 408ms/step - loss: 0.1941\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 0.1887\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 0.1849\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.1806\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 0.1757\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.1703\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 5s 410ms/step - loss: 0.1655\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 5s 411ms/step - loss: 0.1632\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 0.1572\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.1528\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 5s 422ms/step - loss: 0.1498\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.1454\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 5s 427ms/step - loss: 0.1428\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.1371\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.1344\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 5s 413ms/step - loss: 0.1303\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 0.1285\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.1232\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.1195\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 0.1168\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 5s 402ms/step - loss: 0.1132\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.1110\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 5s 400ms/step - loss: 0.1078\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.1050\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.1008\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 5s 402ms/step - loss: 0.0987\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.0956\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.0946\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.0902\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 0.0873\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 5s 415ms/step - loss: 0.0857\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 0.0834\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.0801\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 5s 416ms/step - loss: 0.0783\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.0755\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 0.0746\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 5s 427ms/step - loss: 0.0722\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 5s 418ms/step - loss: 0.0696\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 5s 448ms/step - loss: 0.0684\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 5s 407ms/step - loss: 0.0655\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.0643\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.0634\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 0.0598\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 5s 415ms/step - loss: 0.0584\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 5s 406ms/step - loss: 0.0571\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 5s 411ms/step - loss: 0.0557\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.0551\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.0519\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.0513\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 5s 408ms/step - loss: 0.0494\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 5s 412ms/step - loss: 0.0478\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 5s 409ms/step - loss: 0.0467\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 5s 408ms/step - loss: 0.0454\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 5s 403ms/step - loss: 0.0444\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 5s 410ms/step - loss: 0.0435\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 5s 415ms/step - loss: 0.0418\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=150 ) \n",
    "model.save( 'model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed83994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a0e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "  \n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30086c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de31b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
