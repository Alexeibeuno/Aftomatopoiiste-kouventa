{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35088b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7003c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"C:/Users/91866/Downloads/archive (3)\"\n",
    "files_list = os.listdir(dir_path + os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa8ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1894\n"
     ]
    }
   ],
   "source": [
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db79e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9428ccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\91866\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\91866\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eee244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "  vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "  tokens_list = []\n",
    "  vocabulary = []\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    tokens = sentence.split()\n",
    "    vocabulary += tokens\n",
    "    tokens_list.append(tokens)\n",
    "  return tokens_list, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88109fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 22) 22\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae30583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74) 74\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e89a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 74, 1894)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print( decoder_output_data.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e0ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 74)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 22, 200)      378800      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 74, 200)      378800      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 74, 200),    320800      ['embedding_1[0][0]',            \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 74, 1894)     380694      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,779,894\n",
      "Trainable params: 1,779,894\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c62f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 21s 670ms/step - loss: 1.2924\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 5s 391ms/step - loss: 1.1164\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 11s 801ms/step - loss: 1.0968\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 7s 586ms/step - loss: 1.0774\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 10s 588ms/step - loss: 1.0581\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 9s 750ms/step - loss: 1.0400\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 7s 441ms/step - loss: 1.0256\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 10s 904ms/step - loss: 1.0123\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 6s 386ms/step - loss: 0.9991\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 9s 805ms/step - loss: 0.9843\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 6s 380ms/step - loss: 0.9700\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 9s 753ms/step - loss: 0.9545\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 7s 423ms/step - loss: 0.9395\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 6s 467ms/step - loss: 0.9239\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 10s 714ms/step - loss: 0.9098\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 5s 376ms/step - loss: 0.8960\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 11s 804ms/step - loss: 0.8806\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.8671\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 11s 972ms/step - loss: 0.8543\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 4s 373ms/step - loss: 0.8409\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 11s 971ms/step - loss: 0.8278\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 5s 405ms/step - loss: 0.8140\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 11s 986ms/step - loss: 0.8024\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 5s 379ms/step - loss: 0.7898\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 11s 991ms/step - loss: 0.7778\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 5s 382ms/step - loss: 0.7657\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 11s 977ms/step - loss: 0.7548\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7424\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 11s 970ms/step - loss: 0.7328\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7212\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 11s 975ms/step - loss: 0.7102\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.6990\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 11s 971ms/step - loss: 0.6882\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 4s 354ms/step - loss: 0.6786\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 11s 977ms/step - loss: 0.6677\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.6562\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 9s 802ms/step - loss: 0.6475\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 6s 365ms/step - loss: 0.6359\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 7s 571ms/step - loss: 0.6268\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 9s 594ms/step - loss: 0.6155\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.6060\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 11s 823ms/step - loss: 0.5964\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.5860\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 11s 965ms/step - loss: 0.5756\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.5663\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 11s 964ms/step - loss: 0.5559\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 5s 375ms/step - loss: 0.5463\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 11s 970ms/step - loss: 0.5370\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 5s 374ms/step - loss: 0.5261\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 11s 971ms/step - loss: 0.5169\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 5s 384ms/step - loss: 0.5090\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 11s 977ms/step - loss: 0.4979\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.4901\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 11s 973ms/step - loss: 0.4806\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.4700\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 11s 979ms/step - loss: 0.4653\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.4526\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 11s 984ms/step - loss: 0.4446\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.4368\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 11s 937ms/step - loss: 0.4268\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 5s 390ms/step - loss: 0.4187\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 11s 998ms/step - loss: 0.4109\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.4016\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 10s 899ms/step - loss: 0.3935\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 5s 370ms/step - loss: 0.3845\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 5s 373ms/step - loss: 0.3776\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 5s 394ms/step - loss: 0.3700\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 5s 404ms/step - loss: 0.3602\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 5s 413ms/step - loss: 0.3539\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 5s 427ms/step - loss: 0.3455\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 0.3387\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 5s 428ms/step - loss: 0.3301\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 5s 432ms/step - loss: 0.3238\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 5s 432ms/step - loss: 0.3166\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.3099\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.3005\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.2965\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.2883\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 5s 443ms/step - loss: 0.2813\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 5s 438ms/step - loss: 0.2755\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 0.2674\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.2639\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.2564\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.2496\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.2454\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.2377\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 5s 435ms/step - loss: 0.2330\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.2284\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 5s 446ms/step - loss: 0.2206\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 5s 445ms/step - loss: 0.2154\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.2108\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.2049\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.1998\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 5s 438ms/step - loss: 0.1957\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.1893\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 5s 438ms/step - loss: 0.1837\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 5s 443ms/step - loss: 0.1810\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 0.1762\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.1700\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.1667\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.1617\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.1590\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 5s 433ms/step - loss: 0.1532\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.1492\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 5s 436ms/step - loss: 0.1455\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 5s 434ms/step - loss: 0.1416\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 5s 438ms/step - loss: 0.1370\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 5s 435ms/step - loss: 0.1339\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.1297\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 5s 435ms/step - loss: 0.1264\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.1236\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 5s 434ms/step - loss: 0.1191\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 5s 442ms/step - loss: 0.1162\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 5s 433ms/step - loss: 0.1116\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.1092\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 5s 440ms/step - loss: 0.1066\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 5s 435ms/step - loss: 0.1033\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.0996\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.0969\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.0944\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 6s 468ms/step - loss: 0.0916\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.0883\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.0864\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 6s 460ms/step - loss: 0.0832\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 6s 505ms/step - loss: 0.0815\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 156s 14s/step - loss: 0.0780\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 9s 808ms/step - loss: 0.0767\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 7s 370ms/step - loss: 0.0742\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 10s 913ms/step - loss: 0.0714\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 6s 393ms/step - loss: 0.0696\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 9s 811ms/step - loss: 0.0691\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 6s 371ms/step - loss: 0.0650\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 8s 686ms/step - loss: 0.0631\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 8s 518ms/step - loss: 0.0615\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 11s 992ms/step - loss: 0.0600\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 5s 383ms/step - loss: 0.0580\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 11s 919ms/step - loss: 0.0558\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 5s 359ms/step - loss: 0.0553\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 9s 829ms/step - loss: 0.0524\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 7s 395ms/step - loss: 0.0507\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 12s 1s/step - loss: 0.0496\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.0489\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 11s 1000ms/step - loss: 0.0471\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 0.0452\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 10s 844ms/step - loss: 0.0454\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 6s 387ms/step - loss: 0.0434\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 9s 772ms/step - loss: 0.0409\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 6s 372ms/step - loss: 0.0402\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 6s 521ms/step - loss: 0.0394\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 10s 605ms/step - loss: 0.0387\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=50, epochs=150 ) \n",
    "model.save( 'model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed83994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a0e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "  \n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30086c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : hi\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 74) for input KerasTensor(type_spec=TensorSpec(shape=(None, 74), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      " hello end\n",
      "Enter question : what are you\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      " i am a big ego i'm not bragging i'm only answering your questions i am not human so how can i am incapable of feeling shame end\n"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de31b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
